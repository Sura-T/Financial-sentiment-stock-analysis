{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # For file handling\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Download necessary NLTK data for sentiment analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stock_data(data_folder, stock_files):\n",
    "    stock_data = {}  # Dictionary to store stock DataFrames\n",
    "    \n",
    "    for file in stock_files:\n",
    "        stock_name = file.split(\"_\")[0]  # Extract stock name (e.g., AAPL, AMZN)\n",
    "        path = os.path.join(data_folder, file)\n",
    "        \n",
    "        # Load CSV into DataFrame\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        # Drop 'Dividends' and 'Stock Splits' if they are all zeros\n",
    "        if 'Dividends' in df.columns and df['Dividends'].nunique() == 1:\n",
    "            df = df.drop(columns=['Dividends'])\n",
    "        if 'Stock Splits' in df.columns and df['Stock Splits'].nunique() == 1:\n",
    "            df = df.drop(columns=['Stock Splits'])\n",
    "        \n",
    "        # Convert 'Date' column to datetime.date format\n",
    "        df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "        \n",
    "        # Add cleaned DataFrame to dictionary\n",
    "        stock_data[stock_name] = df\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "# Define data folder and stock files\n",
    "data_folder = \"../../data/yfinance_data/yfinance_data\"  # Adjust to your folder path\n",
    "stock_files = [\n",
    "    \"AAPL_historical_data.csv\", \"AMZN_historical_data.csv\", \"GOOG_historical_data.csv\",\n",
    "    \"META_historical_data.csv\", \"MSFT_historical_data.csv\", \"NVDA_historical_data.csv\",\n",
    "    \"TSLA_historical_data.csv\"\n",
    "]\n",
    "\n",
    "# Load stock data\n",
    "stock_data = load_stock_data(data_folder, stock_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load news data\n",
    "def load_news_data(news_file):\n",
    "    # Load the CSV file\n",
    "    news_df = pd.read_csv(news_file)\n",
    "\n",
    "    # Display the first few rows of the date column to inspect the format (debugging)\n",
    "    print(news_df['date'].head(10))\n",
    "\n",
    "    # Convert the 'date' column to datetime, handling the timezone and retaining just the date\n",
    "    news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce').dt.date\n",
    "\n",
    "    # Drop rows where 'date' could not be parsed\n",
    "    news_df = news_df.dropna(subset=['date'])\n",
    "\n",
    "    # Retain relevant columns: 'date' and 'headline'\n",
    "    news_df = news_df[['date', 'headline']]\n",
    "\n",
    "    # Perform Sentiment Analysis\n",
    "    news_df['sentiment_score'] = news_df['headline'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "    # Group by date and calculate the average daily sentiment\n",
    "    avg_sentiment = news_df.groupby('date')['sentiment_score'].mean().reset_index()\n",
    "    avg_sentiment.rename(columns={'sentiment_score': 'avg_sentiment'}, inplace=True)\n",
    "\n",
    "    return avg_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correlation(stock_data, news_sentiment):\n",
    "    results = {}\n",
    "    for stock_name, stock_df in stock_data.items():\n",
    "        # Merge stock data with news sentiment on dates\n",
    "        merged_df = pd.merge(\n",
    "            stock_df, news_sentiment, \n",
    "            left_on='Date', right_on='date', \n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        # Drop redundant 'date' column\n",
    "        merged_df = merged_df.drop(columns=['date'])\n",
    "        \n",
    "        # Calculate daily stock returns\n",
    "        merged_df['Daily_Return'] = merged_df['Close'].pct_change()\n",
    "        \n",
    "        # Drop NaN values (due to percentage change)\n",
    "        merged_df = merged_df.dropna()\n",
    "        \n",
    "        # Calculate Pearson correlation between sentiment and returns\n",
    "        correlation = merged_df['Daily_Return'].corr(merged_df['avg_sentiment'])\n",
    "        results[stock_name] = correlation\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths and file names\n",
    "data_folder = \"../../data/yfinance_data/yfinance_data\"  # Adjust to your data folder path\n",
    "news_file = os.path.join(data_folder, \"raw_analyst_ratings.csv\")\n",
    "\n",
    "# List of stock files\n",
    "stock_files = [\n",
    "    \"AAPL_historical_data.csv\", \"AMZN_historical_data.csv\", \n",
    "    \"GOOG_historical_data.csv\", \"META_historical_data.csv\", \n",
    "    \"MSFT_historical_data.csv\", \"NVDA_historical_data.csv\", \n",
    "    \"TSLA_historical_data.csv\"\n",
    "]\n",
    "\n",
    "# Load stock data and news sentiment data\n",
    "stock_data = load_stock_data(data_folder, stock_files)\n",
    "news_sentiment = load_news_data(news_file)\n",
    "\n",
    "# Perform correlation analysis\n",
    "correlation_results = analyze_correlation(stock_data, news_sentiment)\n",
    "\n",
    "# Display correlation results\n",
    "print(\"\\nCorrelation Between News Sentiment and Stock Returns:\")\n",
    "for stock, correlation in correlation_results.items():\n",
    "    print(f\"{stock}: {correlation:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(correlation_results.keys(), correlation_results.values(), color='skyblue')\n",
    "plt.title(\"Correlation Between News Sentiment and Stock Returns\")\n",
    "plt.xlabel(\"Stock\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.axhline(0, color='grey', linestyle='--')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
